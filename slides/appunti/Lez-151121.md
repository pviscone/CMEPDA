# Lez 15/11/21

## Classificazione di immagini

Un immagine non è altro una matrice con 1,3 o 4 indici (scala di grigio, RGB,RGB+trasparenza)

Volendo possiamo usare una feedforward network per classificare immagini “flattando” l’immagine. In questo modo però si hanno diversi problemi:

- ho perso totalmente la nozione di località, ovvero pixel vicini possono ritrovarsi in punti a caso dell’array flattato.
- Anche per una risoluzione modesta come 600x800 ho più di un milione di pixel, il numero dei parametri è estremamente alto e alla fine la matrici dei pesi sarà estremamente sparsa

Il problema però è invariante per traslazioni , si possono analizzare. Stiamo cercando delle feature nelle immagini che sono fatte da feature locali e non ha importanza dove siano spazialmente nell’immagine

### CNN

Con le CNN possiamo avere reti più piccole che agiscono su un singolo pezzo di immagine e si può ridurre la quantità di dati facendo subsampling, passando da feature locali a feature globali

Una CNN è costruito con un approccio gerarchico. I primi layer imparano le feature locali, il subsampling riduce le informazioni estratte da ogni singola sottoimmagine e infine gli output vengono flattati e passati a una feedforward network

NB: per aumentare il numero di dati di training usualmente si fa data agumentation creando nuove immagine a partire dalle esistenti ruotandole, translandole, aggiungendo rumore, cambiando saturazione, luminosità, etc.

#### Convoluzione

La convoluzione può essere 1D,2D,3D con un Kernel tipicamente quadrato M x M con M dispari (?).

**padding**: ci sono diversi modi per gestire il problema al bordo. (Vedi)

 **pooling** E’ l’operazione che si fa su ogni patch per fare subsampling. I più usati sono il max pooling (prendi il valore massimo nella patch) e l’average pooling (fa la media sugli elementi della patch)

 La convoluzione è un modo per correlare informazioni locali e ridurre la dimensione della rete. 

Se abbiamo oggetti multipli privi di correlazione locale ma multiple feature (es. RGB) se vogliamo processarli nello stesso modo possiamo fare la **1x1 convolution** ovvero fare la convoluzione 1x1xk con k numero delle feature. La simmetria usata qui è data dal fatto che tutti gli oggetti sono gli stessi (????????????????)

un esempio di questa applicazione è dato dal particle identificazion. Abbiamo 4-vettori quindi 4 feature ma ogni vettore è indipendente dagli altri, è “lo stesso oggetto”. Quindi possiamo usare la 1x1 convolution (che in realtà non è una convoluzione)

(INSERISCI IMMAGINE)

### Bounding box

Consideriamo il problema in cui vogliamo identificare la posizione di un determinato oggetto. Quindi cerchiamo le coordinate di due punti opposte, essenzialmente il task è di regressione. (Va dato un box di label (bastano due punti))

Non è semplice estendere all’identificazione di multipli oggetti. Un modo per farlo è l’algoritmo YOLO: Dividi l’immagine in celle, in ogni cella si predice la posizione del bounding box nell’immagine e alla fine si considerano le predizioni fatte per ogni cellette e tramite un algoritmo di clustering si fa una scelta

### Transfer learning

Se impariamo a processare una immagine di un dato size possiamo usarla su immagine di un altra size a patto che la “scala” rimanga lo stesso e che la parte feedforward sia riadattata

Il Tranfer learning è la tecnica con cui si prende un NN allenata per un task e riusarla su un altro Task. Nell’esempio fatto potrebbe bastare semplicemente prendere il pezzo convolutivo della rete e attaccarlo a una nuova feedforward network

## Input a lunghezza variabile: RNN

Esempi di problemi a input con lunghezza variabile sono identificazione dei jet, text translation, etc.

In moldi casi le sequenze hanno ancora un concetto di località e invarianza per translazioni ma anche l’ordine può essere importante (vedi la traduzione di testi)

Altri problemi sono invarianti temporali (es. riconoscere una parola in una frase). In questo caso l’ordine conta e la causalità è importante per risolvere il task

Il modello che si usa in questi casi sono le RNN. Reti in cui gli output di ogni unità ritornano come input dell’unità steso

IMMAGINE

Questa architettura permette alla rete di avere una sorta di memoria degli input precedenti.

### LSTM e GRU

INSERISCI IMMAGINI

Questi sono due tipi di unità con feature addizionali per controllare la loro memoria

Hanno implementato un gate che controlla la memoria permettendo o vietando la memorizzazione di uno specifico input/output/stato interno.

In questo modo l’unità ricorda solo le informazioni rilevanti alla soluzione del task ignorando ciò che non è rilevante

### Time series

Le reti ricorrenti possono essere usate per implementare reti con un numero variabile di input tramite encoding, decoding, sequence2sequence

VEDI ALLA FINE, BOH, ROBE A CASO